{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from six import iteritems\n",
    "import xgboost as xgb\n",
    "from math import log\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "with open('train.txt', encoding='utf-8') as f:\n",
    "    train_data = f.readlines()\n",
    "    f.close\n",
    "with open('test.txt', encoding='utf-8') as f:\n",
    "    test_data = f.readlines()\n",
    "    f.close\n",
    "with open('Dream_of_the_Red_Chamber_seg.txt', encoding='utf-8') as f:\n",
    "    corpus_seg = f.readlines()\n",
    "    f.close\n",
    "with open('Dream_of_the_Red_Chamber.txt', encoding='utf-8') as f:\n",
    "    corpus = f.readlines()\n",
    "    f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test & Train Array Converter\n",
    "TRAIN = []\n",
    "index = 0\n",
    "for row in train_data:\n",
    "    if index == 0:\n",
    "        index += 1\n",
    "        continue\n",
    "    index += 1\n",
    "    x = re.split('\\t|\\n', row)\n",
    "    TRAIN.append([x[1], x[2], x[3]])\n",
    "    \n",
    "TEST = []\n",
    "index = 0\n",
    "for row in test_data:\n",
    "    if index == 0:\n",
    "        index += 1\n",
    "        continue\n",
    "    index += 1\n",
    "    x = re.split('\\t|\\n', row)\n",
    "    TEST.append([x[1], x[2], x[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build The Word Vector\n",
    "TERM_LIST = []\n",
    "for paragraph in corpus_seg:\n",
    "    tokens = paragraph.split()\n",
    "    for token in tokens:\n",
    "        if '_P' in token:\n",
    "            continue\n",
    "        #term = re.sub('_[A-Z | a-z | 0-9]*', '', token)\n",
    "        term = token.split('_')[0]\n",
    "        if term not in TERM_LIST:\n",
    "            TERM_LIST.append(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELATION = {\n",
    "    '祖孫': 0,\n",
    "    '母子': 1,\n",
    "    '母女': 2,\n",
    "    '父子': 3,\n",
    "    '父女': 4,\n",
    "    '兄弟姊妹': 5,\n",
    "    '夫妻': 6,\n",
    "    '姑叔舅姨甥侄': 7,\n",
    "    '遠親': 8,\n",
    "    '主僕': 9,\n",
    "    '師徒': 10,\n",
    "    '居處': 11,\n",
    "}\n",
    "\n",
    "PERSON = {}\n",
    "index = 1\n",
    "for x in TRAIN:\n",
    "    per1 = x[0]\n",
    "    per2 = x[1]\n",
    "    if per1 not in PERSON:\n",
    "        PERSON[per1] = index\n",
    "        index += 1\n",
    "    if per2 not in PERSON:\n",
    "        PERSON[per2] = index\n",
    "        index += 1\n",
    "for x in TEST:\n",
    "    per1 = x[0]\n",
    "    per2 = x[1]\n",
    "    if per1 not in PERSON:\n",
    "        PERSON[per1] = index\n",
    "        index += 1\n",
    "    if per2 not in PERSON:\n",
    "        PERSON[per2] = index\n",
    "        index += 1\n",
    "        \n",
    "GENERAL_NAME = [\n",
    "    '婆子', '夫人', '大姐', '小姐', '嫂子', '姨娘',  '姨媽', '嬸娘', '嫂子', '老娘', '嬤嬤', '奶奶'\n",
    "]\n",
    "\n",
    "Rule1 = ['嫁','娶','婚','買','嫡夫','婦','嫡','妻','妾','連理','太太','夫妻']\n",
    "Rule2 = ['喚作','取名','生','有了','得了','養','懷','爹','娘','父','母','兒','女','女兒','子','孩','乳名','小名']\n",
    "Rule3 = ['請','給','來','請安','磕頭','問好','跪','稟明','奉','喚來','叫','祖','奶','孫','老太太','帶','領']\n",
    "Rule4 = ['長','次','大']\n",
    "Rule5 = ['兄','哥','弟','姊','姐','妹']\n",
    "Rule6 = ['姑','叔','舅','姨','甥','侄','親']\n",
    "Rule7 = ['帶','領','教','徒','門生','師父']\n",
    "Rule8 = ['主','僕','丫','丫頭','丫鬟','心腹','小的','下人','主僕']\n",
    "Rule9 = ['使喚','謝','領','接','扇','差','命','遣','迎','打發','吩咐','喚','罵']\n",
    "\n",
    "RULES = {\n",
    "    '婚配': Rule1, \n",
    "    '直系': Rule2, \n",
    "    '尊卑': Rule3, \n",
    "    '旁系': Rule4, \n",
    "    '手足': Rule5, \n",
    "    '遠親': Rule6, \n",
    "    '師徒': Rule7, \n",
    "    '主僕': Rule8,\n",
    "    '命令': Rule9\n",
    "}\n",
    "\n",
    "CORPUS = corpus\n",
    "\n",
    "PRIORITY = [8, 4, 2, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isGeneralName(name):\n",
    "    if len(name) == 2:\n",
    "        return False\n",
    "    else:\n",
    "        subname = name[1:]\n",
    "        if subname in GENERAL_NAME:\n",
    "            return True\n",
    "\n",
    "def isContainName(content, general_tag, name):\n",
    "    if name in content:\n",
    "        return True\n",
    "    elif(general_tag):\n",
    "        first_name = name[0]\n",
    "        last_name = name[1:]\n",
    "        if first_name in content and last_name in content:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "class FeatureExtractor:\n",
    "    \n",
    "    def __init__(self, per1, per2, rel, file):\n",
    "        self.per1 = per1\n",
    "        self.per2 = per2\n",
    "        self.rel = rel\n",
    "        self.file = file\n",
    "        self.word_vector = {}\n",
    "        self.features = {}\n",
    "        self.initialize()\n",
    "    def initialize(self):\n",
    "        \n",
    "        # FEATURE0 - RELATION\n",
    "        self.features['關係'] = 12\n",
    "        \n",
    "        # Intialized the word vector\n",
    "        for term in TERM_LIST:\n",
    "            self.word_vector[term] = 0\n",
    "            \n",
    "        # Added Person Number(e.g. 曹雪芹: 1, 賈寶玉: 2...)\n",
    "        p1 =  PERSON[self.per2] if PERSON[self.per1] > PERSON[self.per2] else PERSON[self.per1]\n",
    "        p2 =  PERSON[self.per1] if PERSON[self.per1] > PERSON[self.per2] else PERSON[self.per2]\n",
    "        \n",
    "        # FEATURE - PER_1\n",
    "        # FEATURE - PER_2\n",
    "        self.features['角色一'] = p1\n",
    "        self.features['角色二'] = p2\n",
    "            \n",
    "        #FEATURE - RULE\n",
    "        for feature, value in iteritems(RULES):\n",
    "            self.features[feature] = 0\n",
    "            \n",
    "        # FEATURE - LAST_NAME\n",
    "        # Determine the last name is same or not\n",
    "        if self.per1[0] == self.per2[0]:\n",
    "            self.features['姓'] = 100\n",
    "        else:\n",
    "            self.features['姓'] = 0\n",
    "    def extract(self, content, priority):\n",
    "        weight = priority\n",
    "        tokens = content.split()\n",
    "        # Relation in the content\n",
    "        if self.rel in tokens:\n",
    "            self.features['關係'] = RELATION[self.rel]\n",
    "        for token in tokens:\n",
    "            \n",
    "            if '_P' in token:\n",
    "                continue\n",
    "            elif '_DE' in token:\n",
    "                continue\n",
    "            elif '_T' in token:\n",
    "                continue\n",
    "            elif '_SHI' in token:\n",
    "                continue\n",
    "            \n",
    "            #term = re.sub('_[A-Z | a-z | 0-9]*', '', token)\n",
    "            term = token.split('_')[0]\n",
    "            for feature, rule in iteritems(RULES):\n",
    "                weight = priority\n",
    "                if term in rule:\n",
    "                    self.features[feature] += 1 * weight                \n",
    "            self.word_vector[term] += 1 * priority\n",
    "    def save(self):\n",
    "        word_freq = ''\n",
    "        feature_str = ''\n",
    "        \n",
    "        for word, freq in iteritems(self.word_vector):\n",
    "            word_freq = word_freq + str(freq) + ','\n",
    "            \n",
    "        for feature, score in iteritems(self.features):\n",
    "            feature_str = feature_str + str(score) + ','\n",
    "            \n",
    "        #self.file.write(str(RELATION[self.REL]) + ',' + word_freq + \",\" + feature_str[:-1] + '\\n')\n",
    "        self.file.write(str(RELATION[self.rel]) + ',' + feature_str[:-1] + '\\n')\n",
    "        #self.file.write(str(RELATION[self.REL]) + ',' + word_freq[:-1] + '\\n')\n",
    "        \n",
    "        \n",
    "class Preprocessor:\n",
    "    \n",
    "    def __init__(self, data, corpus, filename):\n",
    "        self.file = open(filename, 'w');\n",
    "        self.data = data\n",
    "        self.extracted = [None] * len(data)\n",
    "        self.corpus = corpus\n",
    "        self.vector = {}\n",
    "        \n",
    "    def close(self):\n",
    "        self.file.close();\n",
    "        \n",
    "    def transform(self):\n",
    "        index = 0\n",
    "        for row in self.data:\n",
    "            extracted = []\n",
    "            extractor = FeatureExtractor(row[0], row[1], row[2], self.file)\n",
    "            \n",
    "            per1 = row[0]\n",
    "            per2 = row[1]\n",
    "            per1_general = isGeneralName(per1)\n",
    "            per2_general = isGeneralName(per2)\n",
    "            \n",
    "            tag = False\n",
    "            \n",
    "            # Sentence\n",
    "            for paragraph in self.corpus:\n",
    "                sentences = re.split('，|。|？|！|；', paragraph)\n",
    "                for i in range(len(sentences)):\n",
    "                    if isContainName(sentences[i], per1_general, per1) and isContainName(sentences[i], per2_general, per2):\n",
    "                        extractor.extract(sentences[i], PRIORITY[0])\n",
    "                        extracted.append('S: ' + sentences[i])\n",
    "                        if (tag == False):\n",
    "                            tag = True\n",
    "            \n",
    "            # Context\n",
    "            if tag == False:\n",
    "                for paragraph in self.corpus:\n",
    "                    sentences = re.split('，|。|？|！|；', paragraph)\n",
    "                    for i in range(len(sentences)-2):\n",
    "                        context = sentences[i] + sentences[i+1] + sentences[i+2]\n",
    "                        if isContainName(context, per1_general, per1) and isContainName(context, per2_general, per2):\n",
    "                            extractor.extract(context, PRIORITY[1])\n",
    "                            extracted.append('C: ' + context)\n",
    "                            if (tag == False):\n",
    "                                tag = True\n",
    "            # Otherwise\n",
    "            if tag == False:\n",
    "                temp = ['', '']\n",
    "                for paragraph in self.corpus:\n",
    "                    sentences = re.split('，|。|？|！|；', paragraph)\n",
    "                    for sentence in sentences:\n",
    "                        if isContainName(sentence, per1_general, per1) and temp[0] == '':\n",
    "                            temp[0] = sentence\n",
    "                        if isContainName(sentence, per2_general, per2) and temp[1] == '':\n",
    "                            temp[1] = sentence\n",
    "                    if temp[0] != '' and temp[1] != '':\n",
    "                        extractor.extract(temp[0] + ' ' + temp[1], PRIORITY[3])\n",
    "                        extracted.append('O: ' + temp[0] + ' ' + temp[1])\n",
    "                        if tag == False:\n",
    "                            tag = True\n",
    "                        break;\n",
    "                        \n",
    "            # Otherwise\n",
    "            if tag == False:\n",
    "                temp = ['', '']\n",
    "                for paragraph in CORPUS:\n",
    "                    sentences = re.split('，|。|？|！|；', paragraph)\n",
    "                    for sentence in sentences:\n",
    "                        if per1 in sentence and temp[0] == '':\n",
    "                            temp[0] = sentence\n",
    "                        if per2 in sentence and temp[1] == '':\n",
    "                            temp[1] = sentence\n",
    "                    if temp[0] != '' and temp[1] != '':\n",
    "                        extracted_content = temp[0] + ' ' + temp[1]\n",
    "                        extracted.append('R: ' + extracted_content)\n",
    "                        break;\n",
    "                \n",
    "            self.extracted[index] = extracted\n",
    "            index +=1\n",
    "            extractor.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateFeatureFile(TRAIN, TEST, corpus_seg)\n",
    "xgboost_preds = xgboostTraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['賈敏', '林如海', '夫妻']\n",
      "祖孫=夫妻\n",
      "['賈璜', '金氏', '夫妻']\n",
      "祖孫=夫妻\n",
      "['賈珠', '李紈', '夫妻']\n",
      "母子=夫妻\n",
      "['史太君', '賈代善', '夫妻']\n",
      "祖孫=夫妻\n",
      "['王熙鳳', '賈璉', '夫妻']\n",
      "母子=夫妻\n",
      "['邢夫人', '賈赦', '夫妻']\n",
      "主僕=夫妻\n",
      "['尤氏', '賈珍', '夫妻']\n",
      "主僕=夫妻\n",
      "['秦可卿', '賈蓉', '夫妻']\n",
      "祖孫=夫妻\n",
      "['胡氏', '賈蓉', '夫妻']\n",
      "祖孫=夫妻\n",
      "['賈代善', '賈敏', '父女']\n",
      "祖孫=父女\n",
      "['賈元春', '賈政', '父女']\n",
      "父子=父女\n",
      "['賈迎春', '賈赦', '父女']\n",
      "父子=父女\n",
      "['賈探春', '賈政', '父女']\n",
      "父子=父女\n",
      "['賈惜春', '賈敬', '父女']\n",
      "祖孫=父女\n",
      "['賈巧姐', '賈璉', '父女']\n",
      "母子=父女\n",
      "['林黛玉', '林如海', '父女']\n",
      "父子=父女\n",
      "['賈演', '賈代化', '父子']\n",
      "祖孫=父子\n",
      "['賈源', '賈代善', '父子']\n",
      "祖孫=父子\n",
      "['賈璉', '賈赦', '父子']\n",
      "祖孫=父子\n",
      "['玻璃', '賈母', '主僕']\n",
      "母子=主僕\n",
      "['翡翠', '賈母', '主僕']\n",
      "母子=主僕\n",
      "['小紅', '王熙鳳', '主僕']\n",
      "祖孫=主僕\n",
      "['豐兒', '王熙鳳', '主僕']\n",
      "祖孫=主僕\n",
      "['寶珠', '秦可卿', '主僕']\n",
      "祖孫=主僕\n",
      "['瑞珠', '秦可卿', '主僕']\n",
      "祖孫=主僕\n",
      "['善姐', '王熙鳳', '主僕']\n",
      "祖孫=主僕\n",
      "['小吉祥兒', '趙姨娘', '主僕']\n",
      "祖孫=主僕\n",
      "['焦大', '賈演', '主僕']\n",
      "祖孫=主僕\n",
      "['王夫人', '王子騰', '兄弟姊妹']\n",
      "父女=兄弟姊妹\n",
      "['王夫人', '王子勝', '兄弟姊妹']\n",
      "祖孫=兄弟姊妹\n",
      "['王仁', '王熙鳳', '兄弟姊妹']\n",
      "祖孫=兄弟姊妹\n",
      "['薛姨媽', '王夫人', '兄弟姊妹']\n",
      "主僕=兄弟姊妹\n",
      "['薛寶琴', '薛蝌', '兄弟姊妹']\n",
      "父子=兄弟姊妹\n",
      "['玉釧', '金釧', '兄弟姊妹']\n",
      "主僕=兄弟姊妹\n",
      "['秦鐘', '秦可卿', '兄弟姊妹']\n",
      "祖孫=兄弟姊妹\n",
      "['花自芳', '襲人', '兄弟姊妹']\n",
      "主僕=兄弟姊妹\n",
      "['傅秋芳', '傅試', '兄弟姊妹']\n",
      "父子=兄弟姊妹\n",
      "['金文翔', '鴛鴦', '兄弟姊妹']\n",
      "夫妻=兄弟姊妹\n",
      "['林黛玉', '賈敏', '母女']\n",
      "祖孫=母女\n",
      "['趙姨娘', '賈探春', '母女']\n",
      "主僕=母女\n",
      "['李紋', '李嬸娘', '母女']\n",
      "祖孫=母女\n",
      "['何婆子', '春燕', '母女']\n",
      "祖孫=母女\n",
      "['何婆子', '小鳩兒', '母女']\n",
      "祖孫=母女\n",
      "['賈蘭', '李紈', '母子']\n",
      "主僕=母子\n",
      "['賈菌', '婁氏', '母子']\n",
      "祖孫=母子\n",
      "['賈芹', '周氏', '母子']\n",
      "夫妻=母子\n",
      "['薛蟠', '薛姨媽', '母子']\n",
      "遠親=母子\n",
      "['薛寶釵', '王夫人', '姑叔舅姨甥侄']\n",
      "主僕=姑叔舅姨甥侄\n",
      "['林黛玉', '王夫人', '姑叔舅姨甥侄']\n",
      "主僕=姑叔舅姨甥侄\n",
      "['金氏', '金榮', '姑叔舅姨甥侄']\n",
      "祖孫=姑叔舅姨甥侄\n",
      "['卜世仁', '賈芸', '姑叔舅姨甥侄']\n",
      "母子=姑叔舅姨甥侄\n",
      "['邢岫煙', '邢夫人', '姑叔舅姨甥侄']\n",
      "父女=姑叔舅姨甥侄\n",
      "['賈雨村', '林黛玉', '師徒']\n",
      "主僕=師徒\n",
      "['淨虛', '智能', '師徒']\n",
      "主僕=師徒\n",
      "['賈瑞', '賈代儒', '祖孫']\n",
      "遠親=祖孫\n",
      "['石光珠', '繕國公', '祖孫']\n",
      "夫妻=祖孫\n",
      "['謝鯨', '定城侯', '祖孫']\n",
      "夫妻=祖孫\n",
      "['賈代修', '賈代善', '遠親']\n",
      "祖孫=遠親\n",
      "['賈敕', '賈政', '遠親']\n",
      "祖孫=遠親\n",
      "['賈效', '賈政', '遠親']\n",
      "祖孫=遠親\n",
      "['賈敦', '賈政', '遠親']\n",
      "祖孫=遠親\n",
      "['賈珩', '賈寶玉', '遠親']\n",
      "兄弟姊妹=遠親\n",
      "['賈珖', '賈寶玉', '遠親']\n",
      "兄弟姊妹=遠親\n",
      "['賈荇', '賈瑞', '遠親']\n",
      "祖孫=遠親\n",
      "['賈芷', '賈瑞', '遠親']\n",
      "祖孫=遠親\n",
      "rightRate=0.4196428571428575\n"
     ]
    }
   ],
   "source": [
    "rule_based_result = ruleBase(TEST, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.158679\n",
      "0.158679\n",
      "0.158679\n",
      "0.140799\n",
      "0.158679\n",
      "0.140799\n",
      "0.158679\n",
      "0.140799\n",
      "0.158679\n",
      "0.158679\n",
      "0.140799\n",
      "0.140799\n",
      "0.140799\n",
      "0.140799\n",
      "0.140799\n",
      "0.140799\n",
      "0.155635\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "result = mergeEvaluation(xgboost_preds, rule_based_result, 0.140624)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFeatureFile(train, test, corpus):\n",
    "    # Training Data & Testing Data Transformation\n",
    "    pre1 = Preprocessor(train, corpus, 'ftrain.txt')\n",
    "    pre1.transform()\n",
    "    pre1.close()\n",
    "\n",
    "    pre2 = Preprocessor(test, corpus, 'ftest.txt')\n",
    "    pre2.transform()\n",
    "    pre2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def xgboostTraining():\n",
    "    dtrain = xgb.DMatrix('ftrain.txt')\n",
    "    dtest = xgb.DMatrix('ftest.txt')\n",
    "    # specify parameters via map\n",
    "    param = {}\n",
    "    # use softmax multi-class classification\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    # scale weight of positive examples\n",
    "    param['eta'] = 0.1126\n",
    "    param['max_depth'] = 2\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 12\n",
    "    num_round = 2\n",
    "    bst = xgb.train(param, dtrain, num_round)\n",
    "    # make prediction\n",
    "    bst.save_model('temp.txt')\n",
    "    bst = xgb.Booster(param)\n",
    "    bst.load_model('temp.txt')\n",
    "    preds = bst.predict(dtest)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeEvaluation(xgboost_preds, rule_based_result, threshold):\n",
    "    error = 0\n",
    "    preds = xgboost_preds\n",
    "    result = rule_based_result\n",
    "    \n",
    "    for i in range(112):\n",
    "        prob = np.amax(preds[i])\n",
    "        label = preds[i].tolist().index(prob)\n",
    "        test_label = TEST[i][2]\n",
    "        if prob < threshold:\n",
    "            if result[i] != test_label:\n",
    "                error += 1;\n",
    "        else:\n",
    "            if (label != RELATION[test_label]):\n",
    "                error += 1;\n",
    "                print(prob)\n",
    "    return(1 - error/112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person:\n",
    "    def __init__(self, name):\n",
    "        self.name = name;\n",
    "        self.alias = '';\n",
    "        self.lastName = name[0];\n",
    "        self.gender = 0 # Unknown: 0, Male: 1, Female: 2\n",
    "        self.hasMaleHead = False\n",
    "        self.hasAliasName = False\n",
    "        self.initialize()\n",
    "    def initialize(self):\n",
    "        for f in ['姐','母','娘','媽','奶','嬤']:\n",
    "            if (f in self.name):\n",
    "                self.hasMaleHead = True\n",
    "                break\n",
    "        for f in ['嬤','母','姐','姊','妹','太','夫人','氏','娘','女','姑','姨']:\n",
    "            if (f in self.name):\n",
    "                self.gender = 2\n",
    "                break\n",
    "        if (len(self.name) == 3 and self.name[1:] not in GENERAL_NAME):\n",
    "            self.alias = self.name[1:]\n",
    "            self.hasAliasName = True\n",
    "    def compareLastName(self, p2):\n",
    "        if self.lastName == p2.lastName:\n",
    "            return True\n",
    "        return False\n",
    "    def validName(self):\n",
    "        if (self.hasAliasName):\n",
    "            return self.alias\n",
    "        return self.name\n",
    "    def isFemale(self):\n",
    "        if (self.gender == 2):\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(corpus,term_dic): #Create function (arg1,arg2....)\n",
    "    # treat every paragraph as a document : N=num_of_para\n",
    "    num_of_para=len(corpus)\n",
    "    temp_dic={}\n",
    "    for term in term_dic:#有的兩個最終都=0，為什麼？？！？！\n",
    "        doc_freq=0\n",
    "        term_freq=0\n",
    "        for paragraph in corpus:\n",
    "            if (paragraph.find(term)>=0):\n",
    "                doc_freq+=1\n",
    "                term_freq+=paragraph.count(term)     \n",
    "        if doc_freq==0:\n",
    "            weight=0\n",
    "        else:\n",
    "            weight=(1 + math.log10(term_freq)) * math.log10(num_of_para/doc_freq)\n",
    "        temp_dic[term] = weight\n",
    "    return temp_dic\n",
    "\n",
    "def ruleBase(testData, weight_lastName):\n",
    "    \n",
    "    # Build The Dictinary\n",
    "    term_dic = {} # {term:代號,...}\n",
    "    term_weight_dic = {}\n",
    "    featureDic={}\n",
    "        \n",
    "    for paragraph in corpus_seg:\n",
    "        tokens = paragraph.split()\n",
    "        for token in tokens:\n",
    "            # Normal Norm\n",
    "            if '_Na' in token:\n",
    "                pair = token.split('_')\n",
    "                if pair[0] not in term_dic:\n",
    "                    term_dic[pair[0]]=pair[1]\n",
    "            # 沒有加Nb: 專有名詞！\n",
    "            # Location\n",
    "            elif '_Nc' in token:\n",
    "                pair = token.split('_')\n",
    "                if pair[0] not in term_dic:\n",
    "                    term_dic[pair[0]]=pair[1]\n",
    "            # Time\n",
    "            elif '_Nd' in token:\n",
    "                pair = token.split('_')\n",
    "                if pair[0] not in term_dic:\n",
    "                    term_dic[pair[0]]=pair[1]\n",
    "            elif '_V' in token:\n",
    "                pair = token.split('_')\n",
    "                if pair[0] not in term_dic:\n",
    "                    term_dic[pair[0]]=pair[1]\n",
    "                    \n",
    "    term_weight_dic = tf_idf(corpus,term_dic)\n",
    "    \n",
    "    featureDic['婚配']=['嫁','娶','婚','嫡夫','婦','嫡','妻','妾','連理','太太','夫妻', '媳婦']\n",
    "    featureDic['直系']=['喚作','取名','生','有了','得了','養','懷','爹','娘','父','母','兒','女','女兒','子','孩','乳名','小名']\n",
    "    featureDic['尊卑']=['請','給','來','請安','磕頭','問好','跪','稟明','奉','喚來','叫','祖','奶','孫','老太太','帶','領']\n",
    "    featureDic['旁系']=['長','次','大']\n",
    "    featureDic['手足']=['兄','哥','弟','姊','姐','妹']\n",
    "    featureDic['遠親']=['姑','叔','舅','姨','甥','侄','親']\n",
    "    featureDic['師徒']=['帶','領','教','徒','門生','師父']\n",
    "    featureDic['主僕']=['主','僕','丫','丫頭','丫鬟','心腹','小的','下人','主僕']\n",
    "    featureDic['命令']=['使喚','謝','領','接','扇','差','命','遣','迎','打發','吩咐','喚','罵']\n",
    "    featureDic['女性']=['嬤','母','姐','姊','妹','太','夫人','氏','娘','女','姑','姨']\n",
    "    featureDic['父姓']=['姐','母','娘','媽','奶','嬤']    # 若冠夫姓或父姓，可能會出現的稱呼\n",
    "    featureDic['地點']=[]\n",
    "    for key in term_dic:\n",
    "        if 'Nc' in term_dic[key]:\n",
    "            featureDic['地點'].append(key)\n",
    "            \n",
    "    relationDic={'祖孫':0, '母子':1, '母女':2, '父子':3, '父女':4, '兄弟姊妹':5,'夫妻':6,\n",
    "                 '姑叔舅姨甥侄':7,'遠親':8,'主僕':9, '師徒':10,'居處':11 }\n",
    "    \n",
    "\n",
    "\n",
    "    preFile = open('Segpreprocess.txt','w') \n",
    "\n",
    "    rightRelation=[]\n",
    "    judgeRelation=[]\n",
    "    \n",
    "    # search corpus by two entities and relationship\n",
    "    for row in testData:\n",
    "        oneLine=[]\n",
    "        oneSentence=[]\n",
    "        threeSentences=[]\n",
    "        oneParagraph=[]\n",
    "        rightRelation.append(row[2])\n",
    "        # Rule1: 其中一個是地方就不用做feature list判斷了，一定是居處\n",
    "        if (row[0] in featureDic['地點']) or (row[1] in featureDic['地點']):\n",
    "            judgeRelation.append('居處')        \n",
    "            continue\n",
    "    \n",
    "        per1 = Person(row[0])\n",
    "        per2 = Person(row[1])\n",
    "        \n",
    "        # Rule2: 三個字人名如果有姓，去掉比較好找。若最後一個字是「娘」代表是姨娘，姓不可以省略\n",
    "        entity1 = per1.validName()\n",
    "        entity2 = per2.validName()\n",
    "\n",
    "            \n",
    "        preFile.write(row[0]+' '+row[1]+' '+row[2]+'\\n')\n",
    "        for paragraph in corpus:\n",
    "            if ((entity1 in paragraph) and (entity2 in paragraph)):\n",
    "                inLine = False\n",
    "                inSentence = False\n",
    "                inThreeSentences = False\n",
    "                lines = re.split('[，；。？！]', paragraph)\n",
    "                for line in lines:\n",
    "                    if ((entity1 in line) and (entity2 in line)):\n",
    "                        inLine = True\n",
    "                        oneLine.append(line)\n",
    "                        preFile.write(\"LINE:\"+line+'\\n')\n",
    "\n",
    "                sentences = re.split('[。？！]', paragraph)\n",
    "                thrSentences = []\n",
    "\n",
    "                for sentence in sentences:\n",
    "                    idx=sentences.index(sentence)\n",
    "                    # create 3-sentences group\n",
    "                    if idx>1:\n",
    "                        thrSentences.append(sentences[idx-2]+\"。\"+sentences[idx-1]+\"。\"+sentences[idx])#中間標點統一以。代替\n",
    "                    # judge if in the list\n",
    "                    if ((entity1 in sentence) and (entity2 in sentence)):\n",
    "                        inSentence = True\n",
    "                        # 不能跟前面重複，中間沒逗點再加\n",
    "                        commaLoc=[m.start() for m in re.finditer('[，；]', sentence)] # get all locations of '，；' \n",
    "                        hasCommaBetween = False\n",
    "                        for cLoc in commaLoc:#暫不考慮同一人名一句話出現兩次的特例\n",
    "                            a = sentence.find(row[0])\n",
    "                            b = sentence.find(row[1])\n",
    "                            if ((a<cLoc and cLoc<b) or (b<cLoc and cLoc<a)):\n",
    "                                hasCommaBetween = True\n",
    "                                break\n",
    "                        if (hasCommaBetween == True):\n",
    "                            oneSentence.append(sentence)\n",
    "                            preFile.write(\"SENTENCE:\"+sentence+'\\n')\n",
    "\n",
    "                for context in thrSentences:\n",
    "                    if ((entity1 in context) and (entity2 in context)):\n",
    "                        inThreeSentences = True\n",
    "                        # 不能跟前面重複，中間沒。再加\n",
    "                        periodLoc=[m.start() for m in re.finditer('[。]', context)] # get all locations of '。' \n",
    "\n",
    "                        hasPeriodBetween = False\n",
    "                        for pLoc in periodLoc:#暫不考慮同一人名一句話出現兩次的特例\n",
    "                            a = context.find(entity1)\n",
    "                            b = context.find(entity2)\n",
    "                            if ((a<pLoc and pLoc<b) or (b<pLoc and pLoc<a)):\n",
    "                                hasPeriodBetween = True\n",
    "                                break\n",
    "                        if (hasPeriodBetween == True):\n",
    "                            threeSentences.append(context)\n",
    "                            preFile.write(\"CONTEXT:\"+context+'\\n')\n",
    "\n",
    "\n",
    "                if not (inLine or inSentence or inThreeSentences):\n",
    "                    oneParagraph.append(paragraph)\n",
    "                    preFile.write(\"PARAGRAPH:\"+paragraph+'\\n')\n",
    "\n",
    "        # create a dictionary to store appear phrase weight            \n",
    "        term_weight_vector={}\n",
    "        for line in oneLine:\n",
    "            tempLine = line\n",
    "            for term in term_dic:\n",
    "                if term in tempLine:            \n",
    "                    if term not in term_weight_vector:\n",
    "                        term_weight_vector[term]=0\n",
    "                    term_weight_vector[term] += tempLine.count(term) * 16\n",
    "\n",
    "        for context in threeSentences:\n",
    "            tempContext = context\n",
    "            for term in term_dic:\n",
    "                if term in tempContext:            \n",
    "                    if term not in term_weight_vector:\n",
    "                        term_weight_vector[term]=0\n",
    "                    term_weight_vector[term] += tempContext.count(term) * 4\n",
    "                \n",
    "        for sentence in oneSentence:\n",
    "            tempSentence = sentence\n",
    "            for term in term_dic:\n",
    "                if term in tempSentence:            \n",
    "                    if term not in term_weight_vector:\n",
    "                        term_weight_vector[term]=0\n",
    "                    term_weight_vector[term] += tempSentence.count(term) * 2\n",
    "                \n",
    "        for paragraph in oneParagraph:\n",
    "            tempParagraph = paragraph\n",
    "            for term in term_dic:\n",
    "                if term in tempParagraph:            \n",
    "                    if term not in term_weight_vector:\n",
    "                        term_weight_vector[term]=0\n",
    "                    term_weight_vector[term] += tempParagraph.count(term) * 1\n",
    "                \n",
    "        # create feature list that symbolize different relationship\n",
    "        featureList=[0]*12\n",
    "        for term in term_weight_vector:\n",
    "            if term in featureDic['婚配']:\n",
    "                featureList[relationDic['夫妻']]+=term_weight_vector[term]*term_weight_dic[term]\n",
    "            elif term in featureDic['直系']:\n",
    "                featureList[relationDic['父子']]+=term_weight_vector[term]*term_weight_dic[term]\n",
    "                featureList[relationDic['父女']]+=term_weight_vector[term]*term_weight_dic[term]\n",
    "                featureList[relationDic['母子']]+=term_weight_vector[term]*term_weight_dic[term]\n",
    "                featureList[relationDic['母女']]+=term_weight_vector[term]*term_weight_dic[term]\n",
    "            elif term in featureDic['尊卑']:\n",
    "                featureList[relationDic['祖孫']]+=term_weight_vector[term]*term_weight_dic[term]\n",
    "                featureList[relationDic['主僕']]+=term_weight_vector[term]*term_weight_dic[term]\n",
    "                featureList[relationDic['夫妻']]+=term_weight_vector[term]*term_weight_dic[term]\n",
    "            elif term in featureDic['旁系']:\n",
    "                featureList[relationDic['兄弟姊妹']]+=term_weight_vector[term]*term_weight_dic[term]\n",
    "            elif term in featureDic['手足']:\n",
    "                featureList[relationDic['兄弟姊妹']]+=term_weight_vector[term]*term_weight_dic[term]\n",
    "                featureList[relationDic['主僕']]+=term_weight_vector[term]*term_weight_dic[term]\n",
    "            elif term in featureDic['主僕']:\n",
    "                featureList[relationDic['主僕']]+=term_weight_vector[term]*term_weight_dic[term]\n",
    "            elif term in featureDic['命令']:\n",
    "                featureList[relationDic['夫妻']]+=term_weight_vector[term]*term_weight_dic[term]\n",
    "                featureList[relationDic['主僕']]+=term_weight_vector[term]*term_weight_dic[term]\n",
    "                featureList[relationDic['父子']]+=term_weight_vector[term]*term_weight_dic[term]\n",
    "                featureList[relationDic['父女']]+=term_weight_vector[term]*term_weight_dic[term]\n",
    "                featureList[relationDic['母子']]+=term_weight_vector[term]*term_weight_dic[term]\n",
    "                featureList[relationDic['母女']]+=term_weight_vector[term]*term_weight_dic[term]\n",
    "            elif term in featureDic['遠親']:\n",
    "                featureList[relationDic['遠親']]+=term_weight_vector[term]*term_weight_dic[term]\n",
    "            elif term in featureDic['師徒']:\n",
    "                featureList[relationDic['師徒']]+=term_weight_vector[term]*term_weight_dic[term]\n",
    "\n",
    "\n",
    "        # 同姓：不會是主僕（僕人通常是暱稱），且更有可能是父子、父女、祖孫、兄弟姊妹、姑叔舅姨甥侄、遠親\n",
    "        if per1.compareLastName(per2):\n",
    "            featureList[relationDic['主僕']]=0\n",
    "\n",
    "            featureList[relationDic['遠親']] *= weight_lastName\n",
    "            featureList[relationDic['父子']] *= weight_lastName\n",
    "            featureList[relationDic['父女']] *= weight_lastName\n",
    "            featureList[relationDic['祖孫']] *= weight_lastName\n",
    "            featureList[relationDic['兄弟姊妹']] *= weight_lastName\n",
    "            featureList[relationDic['姑叔舅姨甥侄']] *= weight_lastName\n",
    "\n",
    "            # 若冠夫姓或父姓，同姓仍有可能是母子或母女\n",
    "            if not per1.hasMaleHead and not per2.hasMaleHead:\n",
    "                featureList[relationDic['母子']]= 0\n",
    "                featureList[relationDic['母女']]= 0\n",
    "            else:\n",
    "                featureList[relationDic['母子']] *= weight_lastName\n",
    "                featureList[relationDic['母女']] *= weight_lastName\n",
    "\n",
    "\n",
    "        # 有女性就不會是父子、師徒\n",
    "        if per1.isFemale() or per2.isFemale():\n",
    "            featureList[relationDic['父子']] = 0\n",
    "            featureList[relationDic['師徒']] = 0\n",
    "\n",
    "\n",
    "        # 還沒設想值相同的狀況\n",
    "        max_value=featureList.index(max(featureList))\n",
    "\n",
    "\n",
    "        judgeRelation.append(list(relationDic.keys())[list(relationDic.values()).index(max_value)])\n",
    "    preFile.close()            \n",
    "\n",
    "    rightRate=0\n",
    "    for i in range(len(judgeRelation)):\n",
    "        if judgeRelation[i]==rightRelation[i]:\n",
    "            rightRate+=1/len(judgeRelation)\n",
    "        else: \n",
    "            print(testData[i])\n",
    "            print(judgeRelation[i]+\"=\"+rightRelation[i])    \n",
    "    print (\"rightRate=\"+str(rightRate))\n",
    "    return judgeRelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['薛蟠', '香菱', '夫妻']\n",
      "主僕=夫妻\n",
      "['趙姨娘', '賈政', '夫妻']\n",
      "主僕=夫妻\n",
      "['周姨娘', '賈政', '夫妻']\n",
      "主僕=夫妻\n",
      "['嫣紅', '賈赦', '夫妻']\n",
      "母子=夫妻\n",
      "['邢岫煙', '薛蝌', '夫妻']\n",
      "母子=夫妻\n",
      "['秋桐', '賈璉', '夫妻']\n",
      "主僕=夫妻\n",
      "['賈寶玉', '薛寶釵', '夫妻']\n",
      "主僕=夫妻\n",
      "['香菱', '甄士隱', '父女']\n",
      "祖孫=父女\n",
      "['李守中', '李紈', '父女']\n",
      "父子=父女\n",
      "['秦可卿', '秦業', '父女']\n",
      "祖孫=父女\n",
      "['林之孝', '小紅', '父女']\n",
      "祖孫=父女\n",
      "['銀姐', '卜世仁', '父女']\n",
      "夫妻=父女\n",
      "['金彩', '鴛鴦', '父女']\n",
      "母子=父女\n",
      "['邢忠', '邢岫煙', '父女']\n",
      "父子=父女\n",
      "['秦鐘', '秦業', '父子']\n",
      "兄弟姊妹=父子\n",
      "['賴大', '賴尚榮', '父子']\n",
      "兄弟姊妹=父子\n",
      "['綺霰', '賈寶玉', '主僕']\n",
      "夫妻=主僕\n",
      "['春燕', '賈寶玉', '主僕']\n",
      "母子=主僕\n",
      "['墜兒', '賈寶玉', '主僕']\n",
      "母子=主僕\n",
      "['四兒', '賈寶玉', '主僕']\n",
      "母子=主僕\n",
      "['抱琴', '賈元春', '主僕']\n",
      "祖孫=主僕\n",
      "['蟬姐', '賈探春', '主僕']\n",
      "母子=主僕\n",
      "['繡橘', '賈迎春', '主僕']\n",
      "祖孫=主僕\n",
      "['掃花', '賈寶玉', '主僕']\n",
      "祖孫=主僕\n",
      "['引泉', '賈寶玉', '主僕']\n",
      "夫妻=主僕\n",
      "['雙瑞', '賈寶玉', '主僕']\n",
      "夫妻=主僕\n",
      "['雙壽', '賈寶玉', '主僕']\n",
      "夫妻=主僕\n",
      "['來旺', '王熙鳳', '主僕']\n",
      "夫妻=主僕\n",
      "['錢槐', '賈環', '主僕']\n",
      "母子=主僕\n",
      "['昭兒', '賈璉', '主僕']\n",
      "母子=主僕\n",
      "['昭兒', '王熙鳳', '主僕']\n",
      "祖孫=主僕\n",
      "['杏奴', '柳湘蓮', '主僕']\n",
      "夫妻=主僕\n",
      "['慶兒', '王熙鳳', '主僕']\n",
      "祖孫=主僕\n",
      "['王信', '王熙鳳', '主僕']\n",
      "祖孫=主僕\n",
      "['甄士隱', '霍啟', '主僕']\n",
      "母子=主僕\n",
      "['秋桐', '賈赦', '主僕']\n",
      "夫妻=主僕\n",
      "['賈演', '賈源', '兄弟姊妹']\n",
      "祖孫=兄弟姊妹\n",
      "['賈敷', '賈敬', '兄弟姊妹']\n",
      "父子=兄弟姊妹\n",
      "['賈赦', '賈政', '兄弟姊妹']\n",
      "祖孫=兄弟姊妹\n",
      "['賈赦', '賈敏', '兄弟姊妹']\n",
      "祖孫=兄弟姊妹\n",
      "['賈惜春', '賈珍', '兄弟姊妹']\n",
      "父子=兄弟姊妹\n",
      "['王子騰', '王子勝', '兄弟姊妹']\n",
      "父子=兄弟姊妹\n",
      "['邢忠', '邢夫人', '兄弟姊妹']\n",
      "夫妻=兄弟姊妹\n",
      "['春燕', '小鳩兒', '兄弟姊妹']\n",
      "主僕=兄弟姊妹\n",
      "['四姐', '賈瓊', '兄弟姊妹']\n",
      "母子=兄弟姊妹\n",
      "['小霞', '彩霞', '兄弟姊妹']\n",
      "母子=兄弟姊妹\n",
      "['賈母', '賈敏', '母女']\n",
      "祖孫=母女\n",
      "['賈敏', '林黛玉', '母女']\n",
      "祖孫=母女\n",
      "['賈巧姐', '王熙鳳', '母女']\n",
      "祖孫=母女\n",
      "['薛寶釵', '薛姨媽', '母女']\n",
      "遠親=母女\n",
      "['尤老娘', '尤三姐', '母女']\n",
      "母子=母女\n",
      "['夏奶奶', '夏金桂', '母女']\n",
      "祖孫=母女\n",
      "['李貴', '李嬤嬤', '母子']\n",
      "祖孫=母子\n",
      "['胡氏', '金榮', '母子']\n",
      "祖孫=母子\n",
      "['趙嬤嬤', '趙天棟', '母子']\n",
      "祖孫=母子\n",
      "['王嫂子', '賈芸', '母子']\n",
      "祖孫=母子\n",
      "['周氏', '賈芹', '母子']\n",
      "夫妻=母子\n",
      "['史湘雲', '史鼐', '姑叔舅姨甥侄']\n",
      "父子=姑叔舅姨甥侄\n",
      "['史湘雲', '史鼎', '姑叔舅姨甥侄']\n",
      "祖孫=姑叔舅姨甥侄\n",
      "['薛蝌', '薛姨媽', '姑叔舅姨甥侄']\n",
      "遠親=姑叔舅姨甥侄\n",
      "['李嬸娘', '李紈', '姑叔舅姨甥侄']\n",
      "母子=姑叔舅姨甥侄\n",
      "['夏婆子', '春燕', '姑叔舅姨甥侄']\n",
      "祖孫=姑叔舅姨甥侄\n",
      "['張友士', '馮紫英', '師徒']\n",
      "夫妻=師徒\n",
      "['淨虛', '智善', '師徒']\n",
      "主僕=師徒\n",
      "['傅試', '賈政', '師徒']\n",
      "母子=師徒\n",
      "['賈代善', '賈寶玉', '祖孫']\n",
      "父子=祖孫\n",
      "['賈代儒', '賈瑞', '祖孫']\n",
      "遠親=祖孫\n",
      "['賈代化', '賈珍', '祖孫']\n",
      "父子=祖孫\n",
      "['賈敬', '賈蓉', '祖孫']\n",
      "父子=祖孫\n",
      "['賈代善', '賈珠', '祖孫']\n",
      "父子=祖孫\n",
      "['賈政', '賈蘭', '祖孫']\n",
      "父子=祖孫\n",
      "['賈琛', '賈寶玉', '遠親']\n",
      "夫妻=遠親\n",
      "['賈瓊', '賈寶玉', '遠親']\n",
      "父子=遠親\n",
      "['賈璘', '賈寶玉', '遠親']\n",
      "夫妻=遠親\n",
      "['賈萍', '賈瑞', '遠親']\n",
      "祖孫=遠親\n",
      "['賈菖', '賈瑞', '遠親']\n",
      "祖孫=遠親\n",
      "['賈菱', '賈瑞', '遠親']\n",
      "祖孫=遠親\n",
      "['賈蓁', '賈瑞', '遠親']\n",
      "祖孫=遠親\n",
      "['賈藻', '賈瑞', '遠親']\n",
      "祖孫=遠親\n",
      "['賈蘅', '賈瑞', '遠親']\n",
      "祖孫=遠親\n",
      "['賈芬', '賈瑞', '遠親']\n",
      "祖孫=遠親\n",
      "['賈芳', '賈瑞', '遠親']\n",
      "祖孫=遠親\n",
      "['賈芝', '賈瑞', '遠親']\n",
      "祖孫=遠親\n",
      "['尤老娘', '尤二姐', '母女']\n",
      "母子=母女\n",
      "rightRate=0.43999999999999945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['主僕',\n",
       " '主僕',\n",
       " '夫妻',\n",
       " '主僕',\n",
       " '母子',\n",
       " '母子',\n",
       " '夫妻',\n",
       " '夫妻',\n",
       " '主僕',\n",
       " '夫妻',\n",
       " '夫妻',\n",
       " '夫妻',\n",
       " '主僕',\n",
       " '祖孫',\n",
       " '父子',\n",
       " '祖孫',\n",
       " '祖孫',\n",
       " '夫妻',\n",
       " '母子',\n",
       " '父子',\n",
       " '父子',\n",
       " '父子',\n",
       " '父子',\n",
       " '父子',\n",
       " '父子',\n",
       " '父子',\n",
       " '兄弟姊妹',\n",
       " '父子',\n",
       " '兄弟姊妹',\n",
       " '主僕',\n",
       " '主僕',\n",
       " '主僕',\n",
       " '夫妻',\n",
       " '主僕',\n",
       " '主僕',\n",
       " '主僕',\n",
       " '主僕',\n",
       " '母子',\n",
       " '母子',\n",
       " '母子',\n",
       " '主僕',\n",
       " '祖孫',\n",
       " '主僕',\n",
       " '主僕',\n",
       " '主僕',\n",
       " '母子',\n",
       " '主僕',\n",
       " '祖孫',\n",
       " '主僕',\n",
       " '主僕',\n",
       " '主僕',\n",
       " '主僕',\n",
       " '主僕',\n",
       " '主僕',\n",
       " '主僕',\n",
       " '祖孫',\n",
       " '夫妻',\n",
       " '夫妻',\n",
       " '夫妻',\n",
       " '主僕',\n",
       " '夫妻',\n",
       " '主僕',\n",
       " '主僕',\n",
       " '主僕',\n",
       " '主僕',\n",
       " '主僕',\n",
       " '母子',\n",
       " '主僕',\n",
       " '母子',\n",
       " '祖孫',\n",
       " '主僕',\n",
       " '主僕',\n",
       " '夫妻',\n",
       " '主僕',\n",
       " '祖孫',\n",
       " '主僕',\n",
       " '祖孫',\n",
       " '主僕',\n",
       " '母子',\n",
       " '夫妻',\n",
       " '祖孫',\n",
       " '父子',\n",
       " '祖孫',\n",
       " '祖孫',\n",
       " '父子',\n",
       " '兄弟姊妹',\n",
       " '父子',\n",
       " '夫妻',\n",
       " '兄弟姊妹',\n",
       " '兄弟姊妹',\n",
       " '主僕',\n",
       " '兄弟姊妹',\n",
       " '兄弟姊妹',\n",
       " '兄弟姊妹',\n",
       " '母子',\n",
       " '母子',\n",
       " '兄弟姊妹',\n",
       " '祖孫',\n",
       " '祖孫',\n",
       " '祖孫',\n",
       " '遠親',\n",
       " '母子',\n",
       " '祖孫',\n",
       " '母子',\n",
       " '祖孫',\n",
       " '祖孫',\n",
       " '祖孫',\n",
       " '祖孫',\n",
       " '夫妻',\n",
       " '父子',\n",
       " '祖孫',\n",
       " '遠親',\n",
       " '母子',\n",
       " '祖孫',\n",
       " '居處',\n",
       " '居處',\n",
       " '居處',\n",
       " '居處',\n",
       " '夫妻',\n",
       " '主僕',\n",
       " '母子',\n",
       " '祖孫',\n",
       " '父子',\n",
       " '遠親',\n",
       " '祖孫',\n",
       " '祖孫',\n",
       " '父子',\n",
       " '父子',\n",
       " '祖孫',\n",
       " '祖孫',\n",
       " '祖孫',\n",
       " '祖孫',\n",
       " '父子',\n",
       " '父子',\n",
       " '祖孫',\n",
       " '祖孫',\n",
       " '祖孫',\n",
       " '夫妻',\n",
       " '父子',\n",
       " '夫妻',\n",
       " '祖孫',\n",
       " '祖孫',\n",
       " '祖孫',\n",
       " '祖孫',\n",
       " '祖孫',\n",
       " '祖孫',\n",
       " '祖孫',\n",
       " '祖孫',\n",
       " '祖孫',\n",
       " '母子']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ruleBase(TRAIN, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_lastName = [1, 1.25, 1.5, 1.75, 2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
